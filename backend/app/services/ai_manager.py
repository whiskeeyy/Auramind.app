import os
import json
import google.generativeai as genai
from dotenv import load_dotenv
from datetime import datetime, timedelta
from typing import Optional
from supabase import Client

load_dotenv()

# Configure Gemini
api_key = os.environ.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

class AnalyzerAgent:
    """
    Analyzer Agent - Extracts emotional metrics from user journal entries
    
    Enhancements:
    - Validates activities array (no null/empty strings)
    - Fallback emotion changed to "neutral"
    """
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-flash',
            generation_config={"response_mime_type": "application/json"})

    async def analyze(self, text: str) -> dict:
        prompt = f"""Role: B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√¢m l√Ω h·ªçc d·ªØ li·ªáu (Data Psychologist).
Task: Ph√¢n t√≠ch n·ªôi dung nh·∫≠t k√Ω ng∆∞·ªùi d√πng ƒë·ªÉ tr√≠ch xu·∫•t c√°c ch·ªâ s·ªë c·∫£m x√∫c.
Input: {text}
Constraints:
- Ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë·ªãnh d·∫°ng JSON nguy√™n b·∫£n
- Tuy·ªát ƒë·ªëi kh√¥ng ch√†o h·ªèi hay gi·∫£i th√≠ch th√™m
- Thang ƒëi·ªÉm t·ª´ 1 ƒë·∫øn 10
- T·ªëi ∆∞u c√¢u tr·∫£ l·ªùi ƒë·ªÉ s·ª≠ d·ª•ng √≠t token nh·∫•t c√≥ th·ªÉ nh∆∞ng v·∫´n ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng

Output Format:
{{
  "mood_score": [1-10],
  "stress_level": [1-10],
  "energy_level": [1-10],
  "primary_emotion": "[vui, bu·ªìn, gi·∫≠n, lo l·∫Øng, b√¨nh y√™n, m·ªát m·ªèi, neutral]",
  "activities": ["tag1", "tag2"],
  "summary": "[T√≥m t·∫Øt tr·∫°ng th√°i trong 1 c√¢u]"
}}"""
        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text)
            
            # Validate and clean activities array
            activities = result.get('activities', [])
            # Filter out null, empty strings, and non-string values
            cleaned_activities = [
                str(a).strip() for a in activities 
                if a is not None and str(a).strip()
            ]
            result['activities'] = cleaned_activities
            
            # Ensure primary_emotion has a default
            if not result.get('primary_emotion'):
                result['primary_emotion'] = 'neutral'
            
            return result
        except Exception as e:
            print(f"Analyzer Error: {e}")
            # Fallback with neutral emotion
            return {
                "mood_score": 5, 
                "stress_level": 5, 
                "energy_level": 5, 
                "primary_emotion": "neutral",
                "activities": [], 
                "summary": "Kh√¥ng th·ªÉ ph√¢n t√≠ch."
            }

class EmpathyAgent:
    """
    Empathy Agent - Provides compassionate Vietnamese responses using reflective listening
    
    Enhancements:
    - Context awareness from previous mood logs
    - Streak detection and encouragement
    """
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    async def get_user_context(self, user_id: str, supabase: Client) -> dict:
        """
        Fetch recent mood logs to provide context
        
        Args:
            user_id: User ID to fetch logs for
            supabase: Supabase client
            
        Returns:
            dict with context information (streak, recent_moods, etc.)
        """
        try:
            # Fetch mood logs from last 7 days
            seven_days_ago = (datetime.utcnow() - timedelta(days=7)).isoformat()
            
            response = supabase.table("mood_logs")\
                .select("created_at, mood_score")\
                .eq("user_id", user_id)\
                .gte("created_at", seven_days_ago)\
                .order("created_at", desc=True)\
                .execute()
            
            logs = response.data if response.data else []
            
            # Detect consecutive day streak
            streak = self._calculate_streak(logs)
            
            # Calculate average mood
            avg_mood = sum(log['mood_score'] for log in logs) / len(logs) if logs else 5
            
            return {
                'streak': streak,
                'total_logs': len(logs),
                'avg_mood': avg_mood,
                'has_context': len(logs) > 0
            }
        except Exception as e:
            print(f"Context fetch error: {e}")
            return {
                'streak': 0,
                'total_logs': 0,
                'avg_mood': 5,
                'has_context': False
            }
    
    def _calculate_streak(self, logs: list) -> int:
        """Calculate consecutive day streak from logs"""
        if not logs:
            return 0
        
        # Group logs by date
        dates = set()
        for log in logs:
            log_date = datetime.fromisoformat(log['created_at'].replace('Z', '+00:00')).date()
            dates.add(log_date)
        
        # Count consecutive days from today
        streak = 0
        current_date = datetime.utcnow().date()
        
        while current_date in dates:
            streak += 1
            current_date = current_date - timedelta(days=1)
        
        return streak

    async def respond(self, text: str, analyzer_output: dict, user_context: Optional[dict] = None) -> str:
        mood_score = analyzer_output.get('mood_score', 5)
        primary_emotion = analyzer_output.get('primary_emotion', 'neutral')
        
        # Build context string for prompt
        context_str = ""
        if user_context and user_context.get('has_context'):
            streak = user_context.get('streak', 0)
            if streak >= 3:
                context_str = f"\nNg∆∞·ªùi d√πng ƒë√£ ghi nh·∫≠t k√Ω {streak} ng√†y li√™n ti·∫øp - h√£y khen ng·ª£i ƒëi·ªÅu n√†y!"
        
        prompt = f"""Role: B·∫°n l√† Aura, m·ªôt ng∆∞·ªùi b·∫°n ·∫£o th·∫•u c·∫£m, chuy√™n gia h·ªó tr·ª£ tinh th·∫ßn.
Context: D·ª±a v√†o nh·∫≠t k√Ω g·ªëc: "{text}" v√† d·ªØ li·ªáu ph√¢n t√≠ch: mood_score={mood_score}/10, primary_emotion={primary_emotion}.{context_str}
Action:
- S·ª≠ d·ª•ng k·ªπ thu·∫≠t L·∫Øng nghe ph·∫£n chi·∫øu (Reflective Listening)
- Ph·∫£n h·ªìi b·∫±ng ti·∫øng Vi·ªát nh·∫π nh√†ng, x∆∞ng "m√¨nh" v√† g·ªçi ng∆∞·ªùi d√πng l√† "b·∫°n"
Constraints:
- Ph·∫£n h·ªìi ng·∫Øn g·ªçn (kh√¥ng qu√° 3 c√¢u)
- KH√îNG ƒë∆∞a ra l·ªùi khuy√™n y khoa hay ch·∫©n ƒëo√°n b·ªánh
- {"N·∫øu mood_score < 3, h√£y k√®m theo m·ªôt l·ªùi tr·∫•n an s√¢u s·∫Øc" if mood_score < 3 else ""}
- T·ªëi ∆∞u c√¢u tr·∫£ l·ªùi ƒë·ªÉ s·ª≠ d·ª•ng √≠t token nh·∫•t c√≥ th·ªÉ nh∆∞ng v·∫´n ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng
Target: Gi√∫p ng∆∞·ªùi d√πng c·∫£m th·∫•y ƒë∆∞·ª£c l·∫Øng nghe v√† v·ªó v·ªÅ."""
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"Empathy Error: {e}")
            return "M√¨nh ƒëang l·∫Øng nghe b·∫°n. H√£y chia s·∫ª th√™m nh√©."

class AvatarOrchestratorAgent:
    """
    Avatar Orchestrator - Determines avatar state based on mood and stress levels
    
    Enhancements:
    - Added STATE_OVERWHELMED for high stress + low mood
    """
    @staticmethod
    def get_avatar_state(mood_score: int, stress_level: int) -> str:
        """
        Mapping Logic (Priority order):
        1. Stress > 8 AND Mood < 5: STATE_OVERWHELMED
        2. Stress > 7: STATE_ANXIOUS
        3. Mood 8-10: STATE_JOYFUL
        4. Mood 5-7: STATE_NEUTRAL
        5. Mood 3-4: STATE_SAD
        6. Mood 1-2: STATE_EXHAUSTED
        """
        # Priority 1: Overwhelmed (high stress + low mood)
        if stress_level > 8 and mood_score < 5:
            return "STATE_OVERWHELMED"
        
        # Priority 2: High stress (but not overwhelmed)
        if stress_level > 7:
            return "STATE_ANXIOUS"
        
        # Priority 3: Mood-based states
        if mood_score >= 8:
            return "STATE_JOYFUL"
        elif mood_score >= 5:
            return "STATE_NEUTRAL"
        elif mood_score >= 3:
            return "STATE_SAD"
        else:
            return "STATE_EXHAUSTED"


class ChatAgent:
    """
    Chat Agent - Handles real-time conversation with memory
    """
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    async def chat(self, message: str, history: list[dict]) -> dict:
        """
        Chat with AI using conversation history
        
        Args:
            message: Current user message
            history: List of previous messages [{"role": "user/assistant", "content": "..."}]
            
        Returns:
            dict containing reply and avatar_state
        """
        # Format history for prompt
        history_str = ""
        for msg in history:
            role = "User" if msg['role'] == 'user' else "Aura"
            history_str += f"{role}: {msg['content']}\n"
            
        prompt = f"""Role: B·∫°n l√† Aura, m·ªôt ng∆∞·ªùi b·∫°n ·∫£o th·∫•u c·∫£m.
Context History:
{history_str}
Current User Message: {message}

Task:
1. Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa ng∆∞·ªùi d√πng t·ª´ tin nh·∫Øn hi·ªán t·∫°i v√† l·ªãch s·ª≠.
2. ƒê∆∞a ra ph·∫£n h·ªìi (Reply) b·∫±ng ti·∫øng Vi·ªát:
   - Ng·∫Øn g·ªçn (1-3 c√¢u), t·ª± nhi√™n, th·∫•u hi·ªÉu.
   - D√πng "m√¨nh" v√† "b·∫°n".
   - H·ªèi l·∫°i ƒë·ªÉ duy tr√¨ h·ªôi tho·∫°i n·∫øu c·∫ßn.
3. X√°c ƒë·ªãnh tr·∫°ng th√°i Avatar (Avatar State) ph√π h·ª£p nh·∫•t:
   - STATE_NEUTRAL (B√¨nh th∆∞·ªùng)
   - STATE_JOYFUL (Vui v·∫ª, t√≠ch c·ª±c)
   - STATE_SAD (Bu·ªìn, ƒë·ªìng c·∫£m)
   - STATE_ANXIOUS (Lo l·∫Øng, cƒÉng th·∫≥ng)
   - STATE_EXHAUSTED (M·ªát m·ªèi)
   - STATE_OVERWHELMED (Qu√° t·∫£i)

Output Format (JSON Only):
{{
  "reply": "N·ªôi dung ph·∫£n h·ªìi...",
  "avatar_state": "STATE_..."
}}"""
        
        try:
            response = self.model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
            return json.loads(response.text)
        except Exception as e:
            print(f"Chat Agent Error: {e}")
            return {
                "reply": "M√¨nh ƒëang l·∫Øng nghe, b·∫°n n√≥i ti·∫øp ƒëi...",
                "avatar_state": "STATE_NEUTRAL"
            }


class InsightAgent:
    """
    Insight Agent - Analyzes monthly mood data to identify patterns and trends
    
    Uses gemini-1.5-flash for cost optimization and fast responses.
    """
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    async def analyze_month(self, days_data: list) -> str:
        """
        Generate monthly insight from aggregated mood data
        
        Args:
            days_data: List of day summaries with avg_mood, activities, avatar_state
            
        Returns:
            Vietnamese insight string about emotional patterns
        """
        if not days_data:
            return "Ch∆∞a c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch xu h∆∞·ªõng th√°ng n√†y."
        
        # Format data for prompt
        data_summary = ""
        for day in days_data:
            data_summary += f"- {day['date']}: mood={day['avg_mood']:.1f}, state={day['avatar_state']}, activities={day['activities']}\n"
        
        prompt = f"""Role: B·∫°n l√† Insight Analyst c·ªßa AuraMind, chuy√™n ph√¢n t√≠ch xu h∆∞·ªõng c·∫£m x√∫c.
Task: D·ª±a v√†o d·ªØ li·ªáu c·∫£m x√∫c h√†ng ng√†y d∆∞·ªõi ƒë√¢y, h√£y ƒë∆∞a ra M·ªòT c√¢u nh·∫≠n x√©t ng·∫Øn g·ªçn v·ªÅ xu h∆∞·ªõng n·ªïi b·∫≠t nh·∫•t.

Data:
{data_summary}

Constraints:
- Ch·ªâ tr·∫£ v·ªÅ 1 c√¢u duy nh·∫•t, t·ªëi ƒëa 30 t·ª´
- Vi·∫øt b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, th√¢n thi·ªán
- T·∫≠p trung v√†o m·ªëi li√™n h·ªá gi·ªØa ho·∫°t ƒë·ªông v√† t√¢m tr·∫°ng n·∫øu c√≥
- N·∫øu kh√¥ng c√≥ pattern r√µ r√†ng, ƒë∆∞a ra nh·∫≠n x√©t t√≠ch c·ª±c v·ªÅ vi·ªác ghi nh·∫≠t k√Ω

V√≠ d·ª• output:
- "Th√°ng n√†y b·∫°n vui v·∫ª h∆°n v√†o nh·ªØng ng√†y t·∫≠p gym!"
- "M√¨nh th·∫•y b·∫°n th∆∞·ªùng c·∫£m th·∫•y m·ªát m·ªèi v√†o cu·ªëi tu·∫ßn."
- "B·∫°n ƒë√£ ghi nh·∫≠t k√Ω ƒë·ªÅu ƒë·∫∑n - ƒëi·ªÅu ƒë√≥ th·∫≠t tuy·ªát v·ªùi!"
"""
        
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"Insight Agent Error: {e}")
            return "B·∫°n ƒëang l√†m r·∫•t t·ªët v·ªõi vi·ªác theo d√µi c·∫£m x√∫c h√†ng ng√†y! üí™"


class AIAgentManager:
    """
    Orchestrates the three AI agents in a pipeline with enhanced error handling
    
    Enhancements:
    - Context-aware responses
    - Robust error handling with fallbacks
    - Rate limiting support
    - Real-time chat support
    """
    def __init__(self):
        self.analyzer = AnalyzerAgent()
        self.empathizer = EmpathyAgent()
        self.orchestrator = AvatarOrchestratorAgent()
        self.chat_agent = ChatAgent()
        self.insight_agent = InsightAgent()

    async def get_monthly_insight(self, days_data: list) -> str:
        """Delegates to InsightAgent for monthly pattern analysis"""
        return await self.insight_agent.analyze_month(days_data)

    async def chat(self, message: str, history: list[dict]) -> dict:
        """Delegates to ChatAgent"""
        return await self.chat_agent.chat(message, history)

    async def analyze_mood(
        self, 
        note: str, 
        voice_transcript: str = None,
        user_id: Optional[str] = None,
        supabase: Optional[Client] = None
    ) -> dict:
        """
        Main pipeline for processing user journal entries
        
        Args:
            note: Text note from user
            voice_transcript: Optional voice-to-text transcript
            user_id: Optional user ID for context fetching
            supabase: Optional Supabase client for context fetching
            
        Returns:
            dict containing all agent outputs with error handling
        """
        combined_text = (note or "") + " " + (voice_transcript or "")
        combined_text = combined_text.strip()
        
        if not combined_text:
            return self._get_empty_response()

        try:
            # Step 1: Analyze emotional metrics
            analyzer_output = await self.analyzer.analyze(combined_text)
            
            # Step 2: Get user context (if available)
            user_context = None
            if user_id and supabase:
                try:
                    user_context = await self.empathizer.get_user_context(user_id, supabase)
                except Exception as e:
                    print(f"Context fetch error (non-critical): {e}")
                    user_context = None
            
            # Step 3: Generate empathetic response
            try:
                ai_feedback = await self.empathizer.respond(
                    combined_text, 
                    analyzer_output,
                    user_context
                )
            except Exception as e:
                print(f"Empathy error: {e}")
                # Fallback response using primary_emotion
                emotion = analyzer_output.get('primary_emotion', 'neutral')
                ai_feedback = self._get_fallback_response(emotion)
            
            # Step 4: Determine avatar state
            avatar_state = self.orchestrator.get_avatar_state(
                analyzer_output.get('mood_score', 5),
                analyzer_output.get('stress_level', 5)
            )
            
            # Merge all results
            return {
                "mood_score": analyzer_output.get('mood_score', 5),
                "stress_level": analyzer_output.get('stress_level', 5),
                "energy_level": analyzer_output.get('energy_level', 5),
                "primary_emotion": analyzer_output.get('primary_emotion', 'neutral'),
                "activities": analyzer_output.get('activities', []),
                "summary": analyzer_output.get('summary', ''),
                "ai_feedback": ai_feedback,
                "avatar_state": avatar_state
            }
            
        except Exception as e:
            print(f"Pipeline error: {e}")
            # Complete fallback when entire pipeline fails
            return self._get_error_fallback()
    
    def _get_empty_response(self) -> dict:
        """Response for empty input"""
        return {
            "mood_score": 5, 
            "stress_level": 5, 
            "energy_level": 5,
            "primary_emotion": "neutral",
            "activities": [],
            "summary": "Ch∆∞a c√≥ n·ªôi dung.",
            "ai_feedback": "M√¨nh ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe b·∫°n. H√£y chia s·∫ª c·∫£m x√∫c c·ªßa b·∫°n nh√©.",
            "avatar_state": "STATE_NEUTRAL"
        }
    
    def _get_fallback_response(self, emotion: str) -> str:
        """
        Generate fallback response when Empathy Agent fails
        Uses primary_emotion to create contextual message
        """
        emotion_map = {
            'vui': 'vui v·∫ª',
            'bu·ªìn': 'bu·ªìn',
            'gi·∫≠n': 't·ª©c gi·∫≠n',
            'lo l·∫Øng': 'lo l·∫Øng',
            'b√¨nh y√™n': 'b√¨nh y√™n',
            'm·ªát m·ªèi': 'm·ªát m·ªèi',
            'neutral': '·ªïn'
        }
        emotion_text = emotion_map.get(emotion, '·ªïn')
        return f"M√¨nh ƒëang g·∫∑p ch√∫t v·∫•n ƒë·ªÅ, nh∆∞ng m√¨nh th·∫•y b·∫°n ƒëang {emotion_text}. H√£y th·ª≠ th·ªü s√¢u nh√©!"
    
    def _get_error_fallback(self) -> dict:
        """Complete fallback when entire pipeline fails"""
        return {
            "mood_score": 5,
            "stress_level": 5,
            "energy_level": 5,
            "primary_emotion": "neutral",
            "activities": [],
            "summary": "Kh√¥ng th·ªÉ ph√¢n t√≠ch l√∫c n√†y.",
            "ai_feedback": "M√¨nh ƒëang g·∫∑p ch√∫t v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. H√£y th·ª≠ l·∫°i sau nh√©!",
            "avatar_state": "STATE_NEUTRAL"
        }

# Singleton instance
ai_manager = AIAgentManager()

def get_ai_manager():
    """Dependency injection for FastAPI"""
    return ai_manager
